{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONPATH'] = '/Users/g.sarapulov/Projects/draft/archtorch'\n",
    "import sys\n",
    "sys.path.append('/Users/g.sarapulov/Projects/draft/archtorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.input import FileParser, DataSampler, SiameseData, EncodedData\n",
    "from loss.margin import ContrastiveLoss\n",
    "from network.siamese import Siamese, Encoder, Discriminator\n",
    "from train.fit import NetworkTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prefix = '/Users/g.sarapulov/MLProjects/uv/'\n",
    "train_path = path_prefix+'train_db/'\n",
    "test_path = path_prefix+'test_db/'\n",
    "parser = FileParser('.txt', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SiameseData(parser, train_path)\n",
    "test_dataset = SiameseData(parser, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Siamese(Encoder())\n",
    "loss = ContrastiveLoss(margin=1.)\n",
    "trainer = NetworkTrainer(train_dataset, test_dataset, log_interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0/52284 (0%)]\tLoss: 0.068244\n",
      "Epoch: 1/20. Train set: Average loss: 0.0311\n",
      "Epoch: 1/20. Validation set: Average loss: 0.0291\n",
      "Train: [0/52284 (0%)]\tLoss: 0.028652\n",
      "Epoch: 2/20. Train set: Average loss: 0.0265\n",
      "Epoch: 2/20. Validation set: Average loss: 0.0269\n",
      "Train: [0/52284 (0%)]\tLoss: 0.026484\n",
      "Epoch: 3/20. Train set: Average loss: 0.0250\n",
      "Epoch: 3/20. Validation set: Average loss: 0.0282\n",
      "Train: [0/52284 (0%)]\tLoss: 0.026275\n",
      "Epoch: 4/20. Train set: Average loss: 0.0246\n",
      "Epoch: 4/20. Validation set: Average loss: 0.0300\n",
      "Train: [0/52284 (0%)]\tLoss: 0.021380\n",
      "Epoch: 5/20. Train set: Average loss: 0.0238\n",
      "Epoch: 5/20. Validation set: Average loss: 0.0283\n",
      "Train: [0/52284 (0%)]\tLoss: 0.018207\n",
      "Epoch: 6/20. Train set: Average loss: 0.0231\n",
      "Epoch: 6/20. Validation set: Average loss: 0.0273\n",
      "Train: [0/52284 (0%)]\tLoss: 0.026587\n",
      "Epoch: 7/20. Train set: Average loss: 0.0227\n",
      "Epoch: 7/20. Validation set: Average loss: 0.0286\n",
      "Train: [0/52284 (0%)]\tLoss: 0.020188\n",
      "Epoch: 8/20. Train set: Average loss: 0.0218\n",
      "Epoch: 8/20. Validation set: Average loss: 0.0262\n",
      "Train: [0/52284 (0%)]\tLoss: 0.020467\n",
      "Epoch: 9/20. Train set: Average loss: 0.0213\n",
      "Epoch: 9/20. Validation set: Average loss: 0.0275\n",
      "Train: [0/52284 (0%)]\tLoss: 0.018782\n",
      "Epoch: 10/20. Train set: Average loss: 0.0206\n",
      "Epoch: 10/20. Validation set: Average loss: 0.0287\n",
      "Train: [0/52284 (0%)]\tLoss: 0.020110\n",
      "Epoch: 11/20. Train set: Average loss: 0.0205\n",
      "Epoch: 11/20. Validation set: Average loss: 0.0251\n",
      "Train: [0/52284 (0%)]\tLoss: 0.018188\n",
      "Epoch: 12/20. Train set: Average loss: 0.0204\n",
      "Epoch: 12/20. Validation set: Average loss: 0.0278\n",
      "Train: [0/52284 (0%)]\tLoss: 0.026143\n",
      "Epoch: 13/20. Train set: Average loss: 0.0202\n",
      "Epoch: 13/20. Validation set: Average loss: 0.0281\n",
      "Train: [0/52284 (0%)]\tLoss: 0.017125\n",
      "Epoch: 14/20. Train set: Average loss: 0.0196\n",
      "Epoch: 14/20. Validation set: Average loss: 0.0283\n",
      "Train: [0/52284 (0%)]\tLoss: 0.019211\n",
      "Epoch: 15/20. Train set: Average loss: 0.0199\n",
      "Epoch: 15/20. Validation set: Average loss: 0.0291\n",
      "Train: [0/52284 (0%)]\tLoss: 0.018738\n",
      "Epoch: 16/20. Train set: Average loss: 0.0198\n",
      "Epoch: 16/20. Validation set: Average loss: 0.0280\n",
      "Train: [0/52284 (0%)]\tLoss: 0.021505\n",
      "Epoch: 17/20. Train set: Average loss: 0.0197\n",
      "Epoch: 17/20. Validation set: Average loss: 0.0274\n",
      "Train: [0/52284 (0%)]\tLoss: 0.014858\n",
      "Epoch: 18/20. Train set: Average loss: 0.0195\n",
      "Epoch: 18/20. Validation set: Average loss: 0.0261\n",
      "Train: [0/52284 (0%)]\tLoss: 0.015705\n",
      "Epoch: 19/20. Train set: Average loss: 0.0196\n",
      "Epoch: 19/20. Validation set: Average loss: 0.0279\n",
      "Train: [0/52284 (0%)]\tLoss: 0.018158\n",
      "Epoch: 20/20. Train set: Average loss: 0.0200\n",
      "Epoch: 20/20. Validation set: Average loss: 0.0268\n"
     ]
    }
   ],
   "source": [
    "model = trainer.fit_model(model, loss, lr=1e-3, n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import exp\n",
    "import numpy as np\n",
    "def calc_labels(data, model):\n",
    "    scores = []\n",
    "    labels = []\n",
    "    for i in range(len(data)):\n",
    "        ((x0, x1), t) = data.__getitem__(i)\n",
    "        x0, x1 = model(x0, x1)\n",
    "        # score = exp(-(x0 - x1).abs().sum())  # L1\n",
    "        score = exp(-(x0 - x1).norm(2))  # eucledian\n",
    "        # score = (x0 * x1).sum() / x0.norm(2) / x1.norm(2)  # cosine\n",
    "        scores.append(float(score))\n",
    "        labels.append(t)\n",
    "    return np.array(scores), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, labels = calc_labels(test_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6491127 , 0.46002039, 0.69302166, 0.61242247, 0.69981092])"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as m\n",
    "def meter(probs, yval, thr):\n",
    "    threshold = thr\n",
    "    print('roc', m.roc_auc_score(yval, probs))\n",
    "    print('f1', m.f1_score(yval, probs > threshold))\n",
    "    print('accuracy', m.accuracy_score(yval, probs > threshold))\n",
    "    print('precision', m.precision_score(yval, probs > threshold))\n",
    "    print('recall', m.recall_score(yval, probs > threshold))\n",
    "    cm = m.confusion_matrix(yval, probs > threshold)\n",
    "    print('false acceptance', cm[0, 1] / cm[0, :].sum())\n",
    "    print('false rejection', cm[1, 0] / cm[1, :].sum())\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc 0.9572200051096369\n",
      "f1 0.8891213389121339\n",
      "accuracy 0.8887722980062959\n",
      "precision 0.8966244725738397\n",
      "recall 0.8817427385892116\n",
      "false acceptance 0.1040339702760085\n",
      "false rejection 0.11825726141078838\n",
      "[[422  49]\n",
      " [ 57 425]]\n"
     ]
    }
   ],
   "source": [
    "meter(scores, labels, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc 0.9669554455445545\n",
      "f1 0.8952590959206174\n",
      "accuracy 0.9003147953830011\n",
      "precision 0.8845315904139434\n",
      "recall 0.90625\n",
      "false acceptance 0.10495049504950495\n",
      "false rejection 0.09375\n",
      "[[452  53]\n",
      " [ 42 406]]\n"
     ]
    }
   ],
   "source": [
    "meter(scores, labels, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, labels = calc_labels(train_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc 0.982190850117159\n",
      "f1 0.9333703600851616\n",
      "accuracy 0.9311644097620687\n",
      "precision 0.9017026756331378\n",
      "recall 0.9673433362753752\n",
      "false acceptance 0.10478551000953289\n",
      "false rejection 0.03265666372462489\n",
      "[[23477  2748]\n",
      " [  851 25208]]\n"
     ]
    }
   ],
   "source": [
    "meter(scores, labels, 0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import exp\n",
    "import numpy as np\n",
    "def calc_all_labels(data, model):\n",
    "    scores = []\n",
    "    labels = []\n",
    "    for i in range(len(data)):\n",
    "        ((x0, x1), t) = data.get_all_pairs(i)\n",
    "        for j, tt in enumerate(t):\n",
    "            xx0, xx1 = model(x0[j], x1[j])\n",
    "            # score = exp((xx0 - xx1).pow(2).sum())\n",
    "            score = exp(-(xx0 - xx1).norm(2))\n",
    "            scores.append(float(score))\n",
    "            labels.append(tt)\n",
    "    return np.array(scores), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_all, labels_all = calc_all_labels(test_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc 0.960803275749552\n",
      "f1 0.14861720852131338\n",
      "accuracy 0.9073265800484475\n",
      "precision 0.08135285388380695\n",
      "recall 0.858177570093458\n",
      "false acceptance 0.09220577119736784\n",
      "false rejection 0.14182242990654206\n",
      "[[816688  82952]\n",
      " [  1214   7346]]\n"
     ]
    }
   ],
   "source": [
    "meter(scores_all, labels_all, 0.52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train = EncodedData(train_dataset, model)\n",
    "enc_test = EncodedData(test_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class LogisticNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticNet, self).__init__()\n",
    "        self.discrimination_net = nn.Sequential(nn.Linear(20, 2), nn.Softmax())\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        output = self.discrimination_net(x1 - x2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/g.sarapulov/Projects/ds_env/lib/python3.6/site-packages/torch/nn/modules/container.py:91: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0/52284 (0%)]\tLoss: 0.685332\n",
      "Epoch: 1/1. Train set: Average loss: 0.6942\n",
      "Epoch: 1/1. Validation set: Average loss: 0.6942\n"
     ]
    }
   ],
   "source": [
    "discr = LogisticNet()\n",
    "loss = CrossEntropyLoss()\n",
    "trainer_discr = NetworkTrainer(enc_train, enc_test, log_interval=500)\n",
    "discr = trainer_discr.fit_model(discr, loss, lr=1e-3, n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import exp\n",
    "import numpy as np\n",
    "def calc_labels_discr(data, model):\n",
    "    scores = []\n",
    "    labels = []\n",
    "    for i in range(len(data)):\n",
    "        ((x0, x1), t) = data.__getitem__(i)\n",
    "        score = model(x0, x1)[0]\n",
    "        print(score)\n",
    "        # score = exp(-(x0 - x1).abs().sum())  # L1\n",
    "        # score = exp(-(x0 - x1).norm(2))  # eucledian\n",
    "        # score = (x0 * x1).sum() / x0.norm(2) / x1.norm(2)  # cosine\n",
    "        scores.append(float(score))\n",
    "        labels.append(t)\n",
    "    return np.array(scores), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/g.sarapulov/Projects/ds_env/lib/python3.6/site-packages/torch/nn/modules/container.py:91: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4837)\n",
      "tensor(0.4945)\n",
      "tensor(0.4848)\n",
      "tensor(0.5095)\n",
      "tensor(0.5065)\n",
      "tensor(0.5141)\n",
      "tensor(0.4977)\n",
      "tensor(0.4827)\n",
      "tensor(0.4740)\n",
      "tensor(0.4687)\n",
      "tensor(0.4893)\n",
      "tensor(0.5014)\n",
      "tensor(0.4966)\n",
      "tensor(0.4959)\n",
      "tensor(0.5151)\n",
      "tensor(0.5157)\n",
      "tensor(0.4965)\n",
      "tensor(0.5007)\n",
      "tensor(0.4999)\n",
      "tensor(0.5194)\n",
      "tensor(0.4788)\n",
      "tensor(0.5481)\n",
      "tensor(0.4711)\n",
      "tensor(0.4704)\n",
      "tensor(0.4932)\n",
      "tensor(0.5398)\n",
      "tensor(0.5224)\n",
      "tensor(0.5195)\n",
      "tensor(0.4495)\n",
      "tensor(0.5010)\n",
      "tensor(0.5174)\n",
      "tensor(0.4903)\n",
      "tensor(0.4028)\n",
      "tensor(0.4571)\n",
      "tensor(0.4648)\n",
      "tensor(0.4642)\n",
      "tensor(0.5301)\n",
      "tensor(0.5086)\n",
      "tensor(0.5331)\n",
      "tensor(0.5178)\n",
      "tensor(0.5306)\n",
      "tensor(0.5166)\n",
      "tensor(0.4973)\n",
      "tensor(0.4895)\n",
      "tensor(0.4904)\n",
      "tensor(0.5250)\n",
      "tensor(0.4790)\n",
      "tensor(0.4637)\n",
      "tensor(0.4779)\n",
      "tensor(0.4971)\n",
      "tensor(0.4733)\n",
      "tensor(0.4895)\n",
      "tensor(0.4861)\n",
      "tensor(0.4530)\n",
      "tensor(0.4861)\n",
      "tensor(0.4829)\n",
      "tensor(0.4901)\n",
      "tensor(0.5223)\n",
      "tensor(0.5493)\n",
      "tensor(0.4661)\n",
      "tensor(0.5059)\n",
      "tensor(0.4895)\n",
      "tensor(0.4516)\n",
      "tensor(0.4978)\n",
      "tensor(0.5120)\n",
      "tensor(0.5039)\n",
      "tensor(0.5046)\n",
      "tensor(0.4895)\n",
      "tensor(0.4991)\n",
      "tensor(0.4978)\n",
      "tensor(0.4948)\n",
      "tensor(0.4837)\n",
      "tensor(0.5346)\n",
      "tensor(0.5202)\n",
      "tensor(0.4485)\n",
      "tensor(0.5571)\n",
      "tensor(0.5254)\n",
      "tensor(0.4727)\n",
      "tensor(0.4815)\n",
      "tensor(0.5368)\n",
      "tensor(0.4920)\n",
      "tensor(0.4834)\n",
      "tensor(0.5168)\n",
      "tensor(0.4943)\n",
      "tensor(0.4889)\n",
      "tensor(0.5142)\n",
      "tensor(0.4811)\n",
      "tensor(0.5011)\n",
      "tensor(0.4764)\n",
      "tensor(0.4894)\n",
      "tensor(0.4986)\n",
      "tensor(0.4809)\n",
      "tensor(0.4805)\n",
      "tensor(0.4863)\n",
      "tensor(0.5206)\n",
      "tensor(0.5061)\n",
      "tensor(0.4785)\n",
      "tensor(0.5079)\n",
      "tensor(0.4802)\n",
      "tensor(0.4960)\n",
      "tensor(0.4839)\n",
      "tensor(0.4830)\n",
      "tensor(0.5060)\n",
      "tensor(0.4865)\n",
      "tensor(0.4923)\n",
      "tensor(0.4943)\n",
      "tensor(0.4992)\n",
      "tensor(0.4720)\n",
      "tensor(0.4995)\n",
      "tensor(0.4715)\n",
      "tensor(0.5012)\n",
      "tensor(0.5050)\n",
      "tensor(0.5326)\n",
      "tensor(0.5402)\n",
      "tensor(0.5303)\n",
      "tensor(0.4692)\n",
      "tensor(0.4922)\n",
      "tensor(0.4983)\n",
      "tensor(0.5031)\n",
      "tensor(0.5108)\n",
      "tensor(0.4654)\n",
      "tensor(0.4526)\n",
      "tensor(0.4858)\n",
      "tensor(0.4609)\n",
      "tensor(0.4902)\n",
      "tensor(0.4834)\n",
      "tensor(0.4981)\n",
      "tensor(0.5136)\n",
      "tensor(0.4589)\n",
      "tensor(0.4958)\n",
      "tensor(0.4913)\n",
      "tensor(0.4743)\n",
      "tensor(0.5052)\n",
      "tensor(0.4893)\n",
      "tensor(0.4766)\n",
      "tensor(0.5057)\n",
      "tensor(0.4831)\n",
      "tensor(0.5048)\n",
      "tensor(0.5089)\n",
      "tensor(0.4992)\n",
      "tensor(0.5074)\n",
      "tensor(0.4945)\n",
      "tensor(0.4759)\n",
      "tensor(0.4731)\n",
      "tensor(0.5148)\n",
      "tensor(0.4983)\n",
      "tensor(0.4808)\n",
      "tensor(0.5075)\n",
      "tensor(0.5193)\n",
      "tensor(0.4656)\n",
      "tensor(0.5333)\n",
      "tensor(0.5029)\n",
      "tensor(0.4929)\n",
      "tensor(0.5033)\n",
      "tensor(0.4968)\n",
      "tensor(0.4743)\n",
      "tensor(0.4559)\n",
      "tensor(0.4887)\n",
      "tensor(0.4717)\n",
      "tensor(0.4805)\n",
      "tensor(0.5482)\n",
      "tensor(0.4632)\n",
      "tensor(0.4700)\n",
      "tensor(0.5034)\n",
      "tensor(0.5248)\n",
      "tensor(0.4805)\n",
      "tensor(0.4660)\n",
      "tensor(0.4983)\n",
      "tensor(0.5021)\n",
      "tensor(0.4888)\n",
      "tensor(0.5106)\n",
      "tensor(0.5148)\n",
      "tensor(0.5307)\n",
      "tensor(0.4970)\n",
      "tensor(0.4886)\n",
      "tensor(0.4918)\n",
      "tensor(0.5040)\n",
      "tensor(0.4593)\n",
      "tensor(0.4918)\n",
      "tensor(0.4932)\n",
      "tensor(0.4640)\n",
      "tensor(0.5205)\n",
      "tensor(0.4767)\n",
      "tensor(0.5017)\n",
      "tensor(0.5101)\n",
      "tensor(0.5094)\n",
      "tensor(0.5190)\n",
      "tensor(0.4713)\n",
      "tensor(0.5290)\n",
      "tensor(0.5217)\n",
      "tensor(0.5000)\n",
      "tensor(0.4965)\n",
      "tensor(0.4640)\n",
      "tensor(0.5160)\n",
      "tensor(0.5082)\n",
      "tensor(0.4850)\n",
      "tensor(0.4852)\n",
      "tensor(0.4911)\n",
      "tensor(0.5296)\n",
      "tensor(0.5151)\n",
      "tensor(0.4616)\n",
      "tensor(0.5044)\n",
      "tensor(0.4685)\n",
      "tensor(0.4859)\n",
      "tensor(0.5039)\n",
      "tensor(0.4734)\n",
      "tensor(0.5016)\n",
      "tensor(0.4875)\n",
      "tensor(0.4552)\n",
      "tensor(0.4609)\n",
      "tensor(0.5317)\n",
      "tensor(0.4781)\n",
      "tensor(0.4801)\n",
      "tensor(0.5029)\n",
      "tensor(0.4909)\n",
      "tensor(0.4761)\n",
      "tensor(0.5724)\n",
      "tensor(0.4934)\n",
      "tensor(0.4717)\n",
      "tensor(0.5379)\n",
      "tensor(0.5082)\n",
      "tensor(0.4867)\n",
      "tensor(0.5003)\n",
      "tensor(0.5139)\n",
      "tensor(0.4622)\n",
      "tensor(0.5292)\n",
      "tensor(0.4636)\n",
      "tensor(0.4147)\n",
      "tensor(0.5141)\n",
      "tensor(0.4495)\n",
      "tensor(0.4550)\n",
      "tensor(0.5020)\n",
      "tensor(0.4798)\n",
      "tensor(0.4742)\n",
      "tensor(0.5119)\n",
      "tensor(0.4987)\n",
      "tensor(0.4857)\n",
      "tensor(0.5162)\n",
      "tensor(0.5017)\n",
      "tensor(0.4924)\n",
      "tensor(0.4991)\n",
      "tensor(0.4899)\n",
      "tensor(0.5137)\n",
      "tensor(0.5090)\n",
      "tensor(0.4743)\n",
      "tensor(0.5011)\n",
      "tensor(0.4995)\n",
      "tensor(0.4935)\n",
      "tensor(0.4575)\n",
      "tensor(0.4906)\n",
      "tensor(0.4776)\n",
      "tensor(0.4721)\n",
      "tensor(0.4902)\n",
      "tensor(0.4930)\n",
      "tensor(0.5122)\n",
      "tensor(0.4568)\n",
      "tensor(0.5072)\n",
      "tensor(0.5108)\n",
      "tensor(0.5058)\n",
      "tensor(0.5152)\n",
      "tensor(0.5153)\n",
      "tensor(0.5077)\n",
      "tensor(0.4966)\n",
      "tensor(0.4619)\n",
      "tensor(0.4874)\n",
      "tensor(0.5084)\n",
      "tensor(0.4853)\n",
      "tensor(0.5013)\n",
      "tensor(0.4836)\n",
      "tensor(0.4767)\n",
      "tensor(0.4919)\n",
      "tensor(0.5025)\n",
      "tensor(0.5139)\n",
      "tensor(0.4850)\n",
      "tensor(0.4858)\n",
      "tensor(0.4770)\n",
      "tensor(0.4836)\n",
      "tensor(0.5195)\n",
      "tensor(0.5157)\n",
      "tensor(0.5233)\n",
      "tensor(0.4654)\n",
      "tensor(0.4787)\n",
      "tensor(0.5029)\n",
      "tensor(0.5208)\n",
      "tensor(0.4661)\n",
      "tensor(0.5209)\n",
      "tensor(0.4591)\n",
      "tensor(0.4531)\n",
      "tensor(0.4876)\n",
      "tensor(0.4951)\n",
      "tensor(0.5169)\n",
      "tensor(0.6284)\n",
      "tensor(0.5016)\n",
      "tensor(0.4960)\n",
      "tensor(0.4847)\n",
      "tensor(0.5280)\n",
      "tensor(0.5007)\n",
      "tensor(0.4906)\n",
      "tensor(0.4800)\n",
      "tensor(0.4760)\n",
      "tensor(0.4770)\n",
      "tensor(0.4888)\n",
      "tensor(0.4830)\n",
      "tensor(0.5471)\n",
      "tensor(0.4476)\n",
      "tensor(0.4647)\n",
      "tensor(0.4466)\n",
      "tensor(0.4749)\n",
      "tensor(0.4804)\n",
      "tensor(0.4789)\n",
      "tensor(0.5295)\n",
      "tensor(0.4746)\n",
      "tensor(0.5117)\n",
      "tensor(0.4998)\n",
      "tensor(0.4604)\n",
      "tensor(0.4912)\n",
      "tensor(0.4838)\n",
      "tensor(0.5003)\n",
      "tensor(0.5181)\n",
      "tensor(0.5093)\n",
      "tensor(0.4964)\n",
      "tensor(0.5045)\n",
      "tensor(0.4996)\n",
      "tensor(0.4683)\n",
      "tensor(0.5144)\n",
      "tensor(0.5126)\n",
      "tensor(0.4630)\n",
      "tensor(0.4665)\n",
      "tensor(0.4981)\n",
      "tensor(0.4811)\n",
      "tensor(0.4845)\n",
      "tensor(0.5186)\n",
      "tensor(0.4957)\n",
      "tensor(0.5090)\n",
      "tensor(0.4683)\n",
      "tensor(0.5250)\n",
      "tensor(0.4940)\n",
      "tensor(0.4858)\n",
      "tensor(0.5038)\n",
      "tensor(0.5375)\n",
      "tensor(0.4991)\n",
      "tensor(0.5320)\n",
      "tensor(0.5131)\n",
      "tensor(0.4905)\n",
      "tensor(0.4793)\n",
      "tensor(0.5219)\n",
      "tensor(0.5109)\n",
      "tensor(0.4700)\n",
      "tensor(0.4665)\n",
      "tensor(0.4290)\n",
      "tensor(0.4954)\n",
      "tensor(0.5084)\n",
      "tensor(0.4798)\n",
      "tensor(0.4420)\n",
      "tensor(0.4474)\n",
      "tensor(0.4819)\n",
      "tensor(0.4281)\n",
      "tensor(0.5065)\n",
      "tensor(0.4996)\n",
      "tensor(0.4927)\n",
      "tensor(0.4859)\n",
      "tensor(0.4892)\n",
      "tensor(0.4288)\n",
      "tensor(0.5207)\n",
      "tensor(0.4955)\n",
      "tensor(0.4747)\n",
      "tensor(0.4793)\n",
      "tensor(0.4887)\n",
      "tensor(0.4969)\n",
      "tensor(0.5153)\n",
      "tensor(0.5119)\n",
      "tensor(0.4883)\n",
      "tensor(0.4600)\n",
      "tensor(0.4601)\n",
      "tensor(0.4827)\n",
      "tensor(0.4997)\n",
      "tensor(0.5284)\n",
      "tensor(0.4836)\n",
      "tensor(0.5335)\n",
      "tensor(0.4826)\n",
      "tensor(0.4770)\n",
      "tensor(0.4647)\n",
      "tensor(0.5182)\n",
      "tensor(0.4995)\n",
      "tensor(0.5230)\n",
      "tensor(0.5114)\n",
      "tensor(0.4820)\n",
      "tensor(0.5061)\n",
      "tensor(0.4806)\n",
      "tensor(0.5212)\n",
      "tensor(0.4956)\n",
      "tensor(0.4776)\n",
      "tensor(0.4519)\n",
      "tensor(0.4904)\n",
      "tensor(0.5028)\n",
      "tensor(0.4717)\n",
      "tensor(0.4936)\n",
      "tensor(0.5036)\n",
      "tensor(0.4821)\n",
      "tensor(0.4979)\n",
      "tensor(0.4900)\n",
      "tensor(0.4277)\n",
      "tensor(0.5122)\n",
      "tensor(0.4748)\n",
      "tensor(0.4944)\n",
      "tensor(0.4528)\n",
      "tensor(0.4597)\n",
      "tensor(0.4921)\n",
      "tensor(0.5086)\n",
      "tensor(0.4899)\n",
      "tensor(0.4545)\n",
      "tensor(0.4964)\n",
      "tensor(0.4932)\n",
      "tensor(0.4740)\n",
      "tensor(0.4888)\n",
      "tensor(0.5176)\n",
      "tensor(0.4984)\n",
      "tensor(0.4788)\n",
      "tensor(0.4849)\n",
      "tensor(0.4803)\n",
      "tensor(0.4949)\n",
      "tensor(0.4830)\n",
      "tensor(0.4864)\n",
      "tensor(0.4830)\n",
      "tensor(0.4771)\n",
      "tensor(0.4752)\n",
      "tensor(0.4776)\n",
      "tensor(0.5092)\n",
      "tensor(0.4635)\n",
      "tensor(0.4778)\n",
      "tensor(0.4372)\n",
      "tensor(0.4805)\n",
      "tensor(0.4861)\n",
      "tensor(0.4719)\n",
      "tensor(0.4818)\n",
      "tensor(0.5033)\n",
      "tensor(0.4672)\n",
      "tensor(0.4488)\n",
      "tensor(0.5381)\n",
      "tensor(0.5025)\n",
      "tensor(0.4583)\n",
      "tensor(0.4940)\n",
      "tensor(0.4834)\n",
      "tensor(0.4317)\n",
      "tensor(0.4885)\n",
      "tensor(0.4931)\n",
      "tensor(0.4842)\n",
      "tensor(0.4805)\n",
      "tensor(0.5285)\n",
      "tensor(0.4794)\n",
      "tensor(0.5042)\n",
      "tensor(0.4825)\n",
      "tensor(0.5375)\n",
      "tensor(0.4984)\n",
      "tensor(0.4679)\n",
      "tensor(0.4997)\n",
      "tensor(0.5169)\n",
      "tensor(0.5243)\n",
      "tensor(0.4904)\n",
      "tensor(0.5181)\n",
      "tensor(0.4773)\n",
      "tensor(0.4770)\n",
      "tensor(0.4905)\n",
      "tensor(0.4968)\n",
      "tensor(0.5202)\n",
      "tensor(0.4864)\n",
      "tensor(0.4987)\n",
      "tensor(0.4853)\n",
      "tensor(0.5221)\n",
      "tensor(0.5192)\n",
      "tensor(0.5005)\n",
      "tensor(0.4984)\n",
      "tensor(0.4875)\n",
      "tensor(0.4891)\n",
      "tensor(0.5258)\n",
      "tensor(0.4962)\n",
      "tensor(0.4548)\n",
      "tensor(0.4794)\n",
      "tensor(0.4812)\n",
      "tensor(0.4752)\n",
      "tensor(0.5075)\n",
      "tensor(0.4809)\n",
      "tensor(0.4894)\n",
      "tensor(0.4648)\n",
      "tensor(0.4916)\n",
      "tensor(0.4954)\n",
      "tensor(0.4874)\n",
      "tensor(0.5203)\n",
      "tensor(0.4950)\n",
      "tensor(0.5047)\n",
      "tensor(0.5012)\n",
      "tensor(0.4530)\n",
      "tensor(0.5136)\n",
      "tensor(0.4816)\n",
      "tensor(0.5032)\n",
      "tensor(0.4641)\n",
      "tensor(0.5066)\n",
      "tensor(0.5089)\n",
      "tensor(0.5044)\n",
      "tensor(0.4992)\n",
      "tensor(0.5009)\n",
      "tensor(0.5095)\n",
      "tensor(0.4678)\n",
      "tensor(0.4944)\n",
      "tensor(0.5134)\n",
      "tensor(0.4645)\n",
      "tensor(0.4933)\n",
      "tensor(0.5212)\n",
      "tensor(0.4650)\n",
      "tensor(0.4974)\n",
      "tensor(0.5061)\n",
      "tensor(0.5019)\n",
      "tensor(0.4993)\n",
      "tensor(0.5257)\n",
      "tensor(0.5001)\n",
      "tensor(0.5057)\n",
      "tensor(0.5260)\n",
      "tensor(0.4698)\n",
      "tensor(0.5034)\n",
      "tensor(0.4733)\n",
      "tensor(0.4912)\n",
      "tensor(0.4991)\n",
      "tensor(0.5125)\n",
      "tensor(0.4636)\n",
      "tensor(0.4894)\n",
      "tensor(0.5403)\n",
      "tensor(0.4962)\n",
      "tensor(0.4777)\n",
      "tensor(0.4854)\n",
      "tensor(0.4886)\n",
      "tensor(0.5067)\n",
      "tensor(0.5078)\n",
      "tensor(0.4920)\n",
      "tensor(0.4840)\n",
      "tensor(0.5192)\n",
      "tensor(0.4784)\n",
      "tensor(0.5460)\n",
      "tensor(0.5210)\n",
      "tensor(0.5111)\n",
      "tensor(0.5023)\n",
      "tensor(0.5334)\n",
      "tensor(0.4677)\n",
      "tensor(0.4690)\n",
      "tensor(0.5248)\n",
      "tensor(0.5786)\n",
      "tensor(0.5044)\n",
      "tensor(0.4636)\n",
      "tensor(0.5496)\n",
      "tensor(0.5699)\n",
      "tensor(0.5103)\n",
      "tensor(0.5248)\n",
      "tensor(0.4876)\n",
      "tensor(0.4802)\n",
      "tensor(0.5183)\n",
      "tensor(0.4637)\n",
      "tensor(0.4533)\n",
      "tensor(0.5117)\n",
      "tensor(0.4939)\n",
      "tensor(0.5517)\n",
      "tensor(0.4931)\n",
      "tensor(0.4777)\n",
      "tensor(0.5058)\n",
      "tensor(0.4709)\n",
      "tensor(0.5041)\n",
      "tensor(0.5187)\n",
      "tensor(0.4843)\n",
      "tensor(0.4840)\n",
      "tensor(0.5065)\n",
      "tensor(0.4979)\n",
      "tensor(0.4869)\n",
      "tensor(0.4846)\n",
      "tensor(0.4885)\n",
      "tensor(0.4688)\n",
      "tensor(0.5280)\n",
      "tensor(0.5054)\n",
      "tensor(0.4896)\n",
      "tensor(0.5501)\n",
      "tensor(0.5098)\n",
      "tensor(0.5043)\n",
      "tensor(0.4947)\n",
      "tensor(0.5391)\n",
      "tensor(0.4384)\n",
      "tensor(0.5202)\n",
      "tensor(0.5572)\n",
      "tensor(0.5216)\n",
      "tensor(0.5043)\n",
      "tensor(0.5301)\n",
      "tensor(0.4707)\n",
      "tensor(0.4931)\n",
      "tensor(0.5124)\n",
      "tensor(0.4739)\n",
      "tensor(0.4916)\n",
      "tensor(0.4947)\n",
      "tensor(0.5068)\n",
      "tensor(0.5160)\n",
      "tensor(0.5419)\n",
      "tensor(0.4368)\n",
      "tensor(0.4968)\n",
      "tensor(0.5381)\n",
      "tensor(0.4852)\n",
      "tensor(0.5033)\n",
      "tensor(0.4747)\n",
      "tensor(0.4974)\n",
      "tensor(0.5302)\n",
      "tensor(0.4985)\n",
      "tensor(0.4920)\n",
      "tensor(0.5125)\n",
      "tensor(0.4741)\n",
      "tensor(0.4517)\n",
      "tensor(0.5198)\n",
      "tensor(0.4919)\n",
      "tensor(0.4899)\n",
      "tensor(0.4788)\n",
      "tensor(0.4875)\n",
      "tensor(0.4876)\n",
      "tensor(0.5091)\n",
      "tensor(0.5133)\n",
      "tensor(0.4751)\n",
      "tensor(0.5050)\n",
      "tensor(0.5232)\n",
      "tensor(0.4838)\n",
      "tensor(0.5274)\n",
      "tensor(0.5068)\n",
      "tensor(0.4897)\n",
      "tensor(0.5056)\n",
      "tensor(0.4752)\n",
      "tensor(0.4893)\n",
      "tensor(0.4949)\n",
      "tensor(0.5108)\n",
      "tensor(0.4862)\n",
      "tensor(0.4785)\n",
      "tensor(0.5025)\n",
      "tensor(0.4879)\n",
      "tensor(0.5142)\n",
      "tensor(0.5034)\n",
      "tensor(0.4909)\n",
      "tensor(0.4796)\n",
      "tensor(0.4955)\n",
      "tensor(0.5021)\n",
      "tensor(0.5284)\n",
      "tensor(0.5139)\n",
      "tensor(0.4618)\n",
      "tensor(0.5364)\n",
      "tensor(0.5490)\n",
      "tensor(0.4521)\n",
      "tensor(0.5209)\n",
      "tensor(0.4851)\n",
      "tensor(0.4749)\n",
      "tensor(0.4887)\n",
      "tensor(0.4746)\n",
      "tensor(0.5016)\n",
      "tensor(0.4904)\n",
      "tensor(0.4880)\n",
      "tensor(0.4918)\n",
      "tensor(0.5215)\n",
      "tensor(0.4891)\n",
      "tensor(0.5175)\n",
      "tensor(0.4832)\n",
      "tensor(0.5261)\n",
      "tensor(0.4769)\n",
      "tensor(0.4876)\n",
      "tensor(0.4933)\n",
      "tensor(0.4896)\n",
      "tensor(0.4943)\n",
      "tensor(0.4298)\n",
      "tensor(0.4941)\n",
      "tensor(0.5323)\n",
      "tensor(0.4964)\n",
      "tensor(0.4912)\n",
      "tensor(0.5231)\n",
      "tensor(0.4916)\n",
      "tensor(0.4883)\n",
      "tensor(0.4688)\n",
      "tensor(0.4999)\n",
      "tensor(0.4981)\n",
      "tensor(0.5155)\n",
      "tensor(0.4934)\n",
      "tensor(0.4475)\n",
      "tensor(0.5303)\n",
      "tensor(0.5098)\n",
      "tensor(0.4894)\n",
      "tensor(0.5423)\n",
      "tensor(0.5021)\n",
      "tensor(0.5071)\n",
      "tensor(0.5086)\n",
      "tensor(0.4898)\n",
      "tensor(0.4941)\n",
      "tensor(0.4877)\n",
      "tensor(0.5123)\n",
      "tensor(0.4622)\n",
      "tensor(0.5033)\n",
      "tensor(0.5137)\n",
      "tensor(0.5327)\n",
      "tensor(0.5052)\n",
      "tensor(0.4996)\n",
      "tensor(0.5666)\n",
      "tensor(0.5121)\n",
      "tensor(0.4894)\n",
      "tensor(0.5049)\n",
      "tensor(0.5157)\n",
      "tensor(0.4857)\n",
      "tensor(0.4716)\n",
      "tensor(0.4816)\n",
      "tensor(0.4811)\n",
      "tensor(0.5074)\n",
      "tensor(0.4908)\n",
      "tensor(0.4558)\n",
      "tensor(0.4978)\n",
      "tensor(0.5072)\n",
      "tensor(0.4926)\n",
      "tensor(0.5218)\n",
      "tensor(0.4844)\n",
      "tensor(0.5351)\n",
      "tensor(0.5177)\n",
      "tensor(0.5382)\n",
      "tensor(0.5156)\n",
      "tensor(0.5187)\n",
      "tensor(0.4832)\n",
      "tensor(0.4823)\n",
      "tensor(0.4749)\n",
      "tensor(0.4869)\n",
      "tensor(0.5208)\n",
      "tensor(0.5051)\n",
      "tensor(0.5075)\n",
      "tensor(0.5152)\n",
      "tensor(0.5233)\n",
      "tensor(0.4834)\n",
      "tensor(0.4940)\n",
      "tensor(0.4873)\n",
      "tensor(0.5074)\n",
      "tensor(0.4774)\n",
      "tensor(0.5134)\n",
      "tensor(0.4446)\n",
      "tensor(0.4760)\n",
      "tensor(0.4926)\n",
      "tensor(0.4574)\n",
      "tensor(0.4368)\n",
      "tensor(0.5470)\n",
      "tensor(0.5223)\n",
      "tensor(0.4788)\n",
      "tensor(0.4892)\n",
      "tensor(0.5364)\n",
      "tensor(0.5047)\n",
      "tensor(0.4944)\n",
      "tensor(0.4956)\n",
      "tensor(0.5260)\n",
      "tensor(0.5258)\n",
      "tensor(0.4740)\n",
      "tensor(0.4994)\n",
      "tensor(0.4922)\n",
      "tensor(0.4823)\n",
      "tensor(0.4768)\n",
      "tensor(0.4793)\n",
      "tensor(0.5299)\n",
      "tensor(0.4965)\n",
      "tensor(0.4882)\n",
      "tensor(0.5093)\n",
      "tensor(0.4927)\n",
      "tensor(0.4833)\n",
      "tensor(0.4889)\n",
      "tensor(0.5164)\n",
      "tensor(0.5330)\n",
      "tensor(0.4911)\n",
      "tensor(0.4762)\n",
      "tensor(0.4962)\n",
      "tensor(0.5437)\n",
      "tensor(0.4721)\n",
      "tensor(0.5076)\n",
      "tensor(0.5235)\n",
      "tensor(0.4665)\n",
      "tensor(0.4922)\n",
      "tensor(0.4826)\n",
      "tensor(0.4834)\n",
      "tensor(0.4964)\n",
      "tensor(0.4880)\n",
      "tensor(0.4819)\n",
      "tensor(0.5125)\n",
      "tensor(0.4948)\n",
      "tensor(0.4951)\n",
      "tensor(0.4989)\n",
      "tensor(0.5217)\n",
      "tensor(0.4793)\n",
      "tensor(0.4964)\n",
      "tensor(0.5132)\n",
      "tensor(0.4816)\n",
      "tensor(0.5218)\n",
      "tensor(0.5210)\n",
      "tensor(0.4759)\n",
      "tensor(0.4792)\n",
      "tensor(0.4904)\n",
      "tensor(0.4651)\n",
      "tensor(0.4696)\n",
      "tensor(0.4824)\n",
      "tensor(0.4968)\n",
      "tensor(0.4755)\n",
      "tensor(0.5084)\n",
      "tensor(0.4705)\n",
      "tensor(0.5148)\n",
      "tensor(0.4928)\n",
      "tensor(0.4801)\n",
      "tensor(0.4955)\n",
      "tensor(0.5040)\n",
      "tensor(0.4938)\n",
      "tensor(0.5176)\n",
      "tensor(0.4795)\n",
      "tensor(0.4928)\n",
      "tensor(0.5001)\n",
      "tensor(0.5054)\n",
      "tensor(0.4731)\n",
      "tensor(0.4825)\n",
      "tensor(0.4809)\n",
      "tensor(0.4833)\n",
      "tensor(0.4877)\n",
      "tensor(0.4857)\n",
      "tensor(0.4743)\n",
      "tensor(0.4862)\n",
      "tensor(0.5145)\n",
      "tensor(0.4718)\n",
      "tensor(0.4943)\n",
      "tensor(0.4916)\n",
      "tensor(0.4984)\n",
      "tensor(0.5047)\n",
      "tensor(0.5018)\n",
      "tensor(0.4908)\n",
      "tensor(0.5036)\n",
      "tensor(0.4886)\n",
      "tensor(0.4911)\n",
      "tensor(0.4673)\n",
      "tensor(0.5197)\n",
      "tensor(0.4877)\n",
      "tensor(0.5129)\n",
      "tensor(0.4843)\n",
      "tensor(0.4945)\n",
      "tensor(0.4833)\n",
      "tensor(0.4971)\n",
      "tensor(0.4972)\n",
      "tensor(0.5246)\n",
      "tensor(0.5491)\n",
      "tensor(0.4651)\n",
      "tensor(0.4840)\n",
      "tensor(0.5012)\n",
      "tensor(0.4810)\n",
      "tensor(0.5242)\n",
      "tensor(0.5184)\n",
      "tensor(0.4834)\n",
      "tensor(0.4745)\n",
      "tensor(0.4616)\n",
      "tensor(0.5009)\n",
      "tensor(0.4422)\n",
      "tensor(0.4932)\n",
      "tensor(0.4845)\n",
      "tensor(0.4887)\n",
      "tensor(0.5169)\n",
      "tensor(0.4882)\n",
      "tensor(0.5166)\n",
      "tensor(0.5093)\n",
      "tensor(0.4567)\n",
      "tensor(0.4852)\n",
      "tensor(0.4921)\n",
      "tensor(0.4954)\n",
      "tensor(0.4830)\n",
      "tensor(0.5083)\n",
      "tensor(0.4788)\n",
      "tensor(0.4698)\n",
      "tensor(0.4889)\n",
      "tensor(0.5163)\n",
      "tensor(0.5297)\n",
      "tensor(0.5169)\n",
      "tensor(0.4625)\n",
      "tensor(0.4948)\n",
      "tensor(0.4968)\n",
      "tensor(0.4778)\n",
      "tensor(0.5069)\n",
      "tensor(0.5033)\n",
      "tensor(0.4694)\n",
      "tensor(0.5001)\n",
      "tensor(0.5190)\n",
      "tensor(0.4675)\n",
      "tensor(0.4925)\n",
      "tensor(0.4763)\n",
      "tensor(0.4706)\n",
      "tensor(0.5377)\n",
      "tensor(0.4971)\n",
      "tensor(0.5051)\n",
      "tensor(0.5039)\n",
      "tensor(0.4641)\n",
      "tensor(0.5047)\n",
      "tensor(0.5324)\n",
      "tensor(0.4623)\n",
      "tensor(0.4755)\n",
      "tensor(0.5151)\n",
      "tensor(0.4825)\n",
      "tensor(0.4710)\n",
      "tensor(0.4696)\n",
      "tensor(0.4956)\n",
      "tensor(0.5063)\n",
      "tensor(0.4562)\n",
      "tensor(0.4765)\n",
      "tensor(0.5174)\n",
      "tensor(0.5171)\n",
      "tensor(0.5360)\n",
      "tensor(0.4973)\n",
      "tensor(0.5303)\n",
      "tensor(0.4852)\n",
      "tensor(0.4649)\n",
      "tensor(0.5254)\n",
      "tensor(0.5137)\n",
      "tensor(0.4694)\n",
      "tensor(0.4950)\n",
      "tensor(0.4975)\n",
      "tensor(0.4997)\n",
      "tensor(0.5048)\n",
      "tensor(0.4788)\n",
      "tensor(0.4606)\n",
      "tensor(0.5105)\n",
      "tensor(0.4780)\n",
      "tensor(0.4013)\n",
      "tensor(0.4820)\n",
      "tensor(0.4976)\n",
      "tensor(0.4864)\n",
      "tensor(0.4772)\n",
      "tensor(0.5001)\n",
      "tensor(0.4995)\n",
      "tensor(0.5090)\n",
      "tensor(0.4908)\n",
      "tensor(0.5002)\n",
      "tensor(0.5336)\n",
      "tensor(0.4965)\n",
      "tensor(0.4881)\n",
      "tensor(0.5557)\n",
      "tensor(0.5202)\n",
      "tensor(0.4511)\n",
      "tensor(0.5157)\n",
      "tensor(0.5191)\n",
      "tensor(0.5131)\n",
      "tensor(0.5159)\n",
      "tensor(0.4820)\n",
      "tensor(0.4909)\n",
      "tensor(0.4671)\n",
      "tensor(0.4878)\n",
      "tensor(0.4964)\n",
      "tensor(0.5234)\n",
      "tensor(0.4831)\n",
      "tensor(0.4712)\n",
      "tensor(0.4876)\n",
      "tensor(0.4958)\n",
      "tensor(0.5302)\n",
      "tensor(0.4711)\n",
      "tensor(0.4996)\n",
      "tensor(0.4790)\n",
      "tensor(0.4533)\n",
      "tensor(0.4671)\n",
      "tensor(0.4681)\n"
     ]
    }
   ],
   "source": [
    "scores, labels = calc_labels_discr(enc_test, discr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_valid_bracket_seq('}{()[]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. locations visited (visa centers, currency exchanges, tour agencies)\n",
    "2. currency operations\n",
    "3. booking activity (transport, hotels, tours)\n",
    "4. travel-specific search activity (sightseeings, country history)\n",
    "5. demographic data (age, gender, marital status)\n",
    "6. employment status (unemployed/ on vacation)\n",
    "7. seasonal data\n",
    "8. last travels data (last trips recency, durations, destinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overfitting is a situation when the model if tuned to explain training data well but fails to generalize on examples not involved in training phase. main reason for this is high complexity of a model. there are several ways to avoid overfitting: reduce model complexity (a tradeoff between bias and variance), apply regularization techniques (constrain model parameters, add dropout), add more data to training dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
