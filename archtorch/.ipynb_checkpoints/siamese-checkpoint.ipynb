{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONPATH'] = '/Users/g.sarapulov/Projects/draft/archtorch'\n",
    "import sys\n",
    "sys.path.append('/Users/g.sarapulov/Projects/draft/archtorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.input import FileParser, DataSampler, SiameseData\n",
    "from loss.margin import ContrastiveLoss\n",
    "from network.siamese import Siamese, Encoder\n",
    "from train.fit import NetworkTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'train_db/'\n",
    "test_path = 'test_db/'\n",
    "parser = FileParser('.txt', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SiameseData(parser, train_path)\n",
    "test_dataset = SiameseData(parser, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Siamese(Encoder())\n",
    "loss = ContrastiveLoss(margin=1.)\n",
    "trainer = NetworkTrainer(train_dataset, test_dataset, log_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0/52284 (0%)]\tLoss: 0.164603\n",
      "Train: [12800/52284 (24%)]\tLoss: 0.134306\n",
      "Train: [25600/52284 (49%)]\tLoss: 0.095927\n",
      "Train: [38400/52284 (73%)]\tLoss: 0.078266\n",
      "Train: [51200/52284 (98%)]\tLoss: 0.071580\n",
      "Epoch: 1/5. Train set: Average loss: 0.0947\n",
      "Epoch: 1/5. Validation set: Average loss: 0.0679\n",
      "Train: [0/52284 (0%)]\tLoss: 0.057696\n",
      "Train: [12800/52284 (24%)]\tLoss: 0.067168\n",
      "Train: [25600/52284 (49%)]\tLoss: 0.064774\n",
      "Train: [38400/52284 (73%)]\tLoss: 0.061796\n",
      "Train: [51200/52284 (98%)]\tLoss: 0.061595\n",
      "Epoch: 2/5. Train set: Average loss: 0.0638\n",
      "Epoch: 2/5. Validation set: Average loss: 0.0631\n",
      "Train: [0/52284 (0%)]\tLoss: 0.058960\n",
      "Train: [12800/52284 (24%)]\tLoss: 0.062008\n",
      "Train: [25600/52284 (49%)]\tLoss: 0.060278\n",
      "Train: [38400/52284 (73%)]\tLoss: 0.060141\n",
      "Train: [51200/52284 (98%)]\tLoss: 0.059341\n",
      "Epoch: 3/5. Train set: Average loss: 0.0604\n",
      "Epoch: 3/5. Validation set: Average loss: 0.0636\n",
      "Train: [0/52284 (0%)]\tLoss: 0.059787\n",
      "Train: [12800/52284 (24%)]\tLoss: 0.060335\n",
      "Train: [25600/52284 (49%)]\tLoss: 0.059560\n",
      "Train: [38400/52284 (73%)]\tLoss: 0.059058\n",
      "Train: [51200/52284 (98%)]\tLoss: 0.059516\n",
      "Epoch: 4/5. Train set: Average loss: 0.0596\n",
      "Epoch: 4/5. Validation set: Average loss: 0.0667\n",
      "Train: [0/52284 (0%)]\tLoss: 0.057996\n",
      "Train: [12800/52284 (24%)]\tLoss: 0.059145\n",
      "Train: [25600/52284 (49%)]\tLoss: 0.057652\n",
      "Train: [38400/52284 (73%)]\tLoss: 0.058534\n",
      "Train: [51200/52284 (98%)]\tLoss: 0.060066\n",
      "Epoch: 5/5. Train set: Average loss: 0.0588\n",
      "Epoch: 5/5. Validation set: Average loss: 0.0633\n"
     ]
    }
   ],
   "source": [
    "model = trainer.fit_model(model, loss, lr=1e-3, n_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import exp\n",
    "import numpy as np\n",
    "def calc_labels(data, model):\n",
    "    scores = []\n",
    "    labels = []\n",
    "    for i in range(len(data)):\n",
    "        ((x0, x1), t) = data.__getitem__(i)\n",
    "        x0, x1 = model(x0, x1)\n",
    "        score = exp(-(x0 - x1).norm(2))\n",
    "        scores.append(float(score))\n",
    "        labels.append(t)\n",
    "    return np.array(scores), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, labels = calc_labels(test_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as m\n",
    "def meter(probs, yval, thr):\n",
    "    threshold = thr\n",
    "    print('roc', m.roc_auc_score(yval, probs))\n",
    "    print('f1', m.f1_score(yval, probs > threshold))\n",
    "    print('accuracy', m.accuracy_score(yval, probs > threshold))\n",
    "    print('precision', m.precision_score(yval, probs > threshold))\n",
    "    print('recall', m.recall_score(yval, probs > threshold))\n",
    "    cm = m.confusion_matrix(yval, probs > threshold)\n",
    "    print('false acceptance', cm[0, 1] / cm[0, :].sum())\n",
    "    print('false rejection', cm[1, 0] / cm[1, :].sum())\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc 0.8823464622433694\n",
      "f1 0.8126858275520318\n",
      "accuracy 0.8016789087093389\n",
      "precision 0.7578558225508318\n",
      "recall 0.8760683760683761\n",
      "false acceptance 0.27010309278350514\n",
      "false rejection 0.12393162393162394\n",
      "[[354 131]\n",
      " [ 58 410]]\n"
     ]
    }
   ],
   "source": [
    "meter(scores, labels, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, labels = calc_labels(train_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc 0.9109688090157814\n",
      "f1 0.7683315621679064\n",
      "accuracy 0.7915232193405248\n",
      "precision 0.8634691635217121\n",
      "recall 0.6920779568863192\n",
      "false acceptance 0.10922153857912638\n",
      "false rejection 0.30792204311368077\n",
      "[[23309  2858]\n",
      " [ 8042 18075]]\n"
     ]
    }
   ],
   "source": [
    "meter(scores, labels, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import exp\n",
    "import numpy as np\n",
    "def calc_all_labels(data, model):\n",
    "    scores = []\n",
    "    labels = []\n",
    "    for i in range(100):\n",
    "        ((x0, x1), t) = data.get_all_pairs(i)\n",
    "        for j, tt in enumerate(t):\n",
    "            xx0, xx1 = model(x0[j], x1[j])\n",
    "            score = exp(-(xx0 - xx1).norm(2))\n",
    "            scores.append(float(score))\n",
    "            labels.append(tt)\n",
    "    return np.array(scores), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_all, labels_all = calc_all_labels(test_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc 0.9022987644809679\n",
      "f1 0.06487731279282141\n",
      "accuracy 0.7528412966597056\n",
      "precision 0.033628318584070796\n",
      "recall 0.9169472502805837\n",
      "false acceptance 0.24870762711864408\n",
      "false rejection 0.08305274971941638\n",
      "[[70922 23478]\n",
      " [   74   817]]\n"
     ]
    }
   ],
   "source": [
    "meter(scores_all, labels_all, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
